{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5df72f18-7779-4ab1-9bc2-971376f22643",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spikingjelly.cext.neuron'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mspikingjelly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcext\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneuron\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MultiStepParametricLIFNode\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mspikingjelly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclock_driven\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layer\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconv3x3\u001b[39m(in_channels, out_channels):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spikingjelly.cext.neuron'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from spikingjelly.cext.neuron import MultiStepParametricLIFNode\n",
    "from spikingjelly.clock_driven import layer\n",
    "\n",
    "def conv3x3(in_channels, out_channels):\n",
    "    return nn.Sequential(\n",
    "        layer.SeqToANNContainer(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        ),\n",
    "        MultiStepParametricLIFNode(init_tau=2.0, detach_reset=True)\n",
    "    )\n",
    "\n",
    "def conv1x1(in_channels, out_channels):\n",
    "    return nn.Sequential(\n",
    "        layer.SeqToANNContainer(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        ),\n",
    "        MultiStepParametricLIFNode(init_tau=2.0, detach_reset=True)\n",
    "    )\n",
    "\n",
    "class SEWBlock(nn.Module):\n",
    "    def __init__(self, in_channels, mid_channels, connect_f=None):\n",
    "        super(SEWBlock, self).__init__()\n",
    "        self.connect_f = connect_f\n",
    "        self.conv = nn.Sequential(\n",
    "            conv3x3(in_channels, mid_channels),\n",
    "            conv3x3(mid_channels, in_channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        out = self.conv(x)\n",
    "        if self.connect_f == 'ADD':\n",
    "            out += x\n",
    "        elif self.connect_f == 'AND':\n",
    "            out *= x\n",
    "        elif self.connect_f == 'IAND':\n",
    "            out = x * (1. - out)\n",
    "        else:\n",
    "            raise NotImplementedError(self.connect_f)\n",
    "\n",
    "        return out\n",
    "\n",
    "class PlainBlock(nn.Module):\n",
    "    def __init__(self, in_channels, mid_channels):\n",
    "        super(PlainBlock, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            conv3x3(in_channels, mid_channels),\n",
    "            conv3x3(mid_channels, in_channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.conv(x)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, mid_channels):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            conv3x3(in_channels, mid_channels),\n",
    "\n",
    "            layer.SeqToANNContainer(\n",
    "                nn.Conv2d(mid_channels, in_channels, kernel_size=3, padding=1, stride=1, bias=False),\n",
    "                nn.BatchNorm2d(in_channels),\n",
    "            ),\n",
    "        )\n",
    "        self.sn = MultiStepParametricLIFNode(init_tau=2.0, detach_reset=True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.sn(x + self.conv(x))\n",
    "\n",
    "\n",
    "class ResNetN(nn.Module):\n",
    "    def __init__(self, layer_list, num_classes, connect_f=None):\n",
    "        super(ResNetN, self).__init__()\n",
    "        in_channels = 2\n",
    "        conv = []\n",
    "\n",
    "        for cfg_dict in layer_list:\n",
    "            channels = cfg_dict['channels']\n",
    "\n",
    "            if 'mid_channels' in cfg_dict:\n",
    "                mid_channels = cfg_dict['mid_channels']\n",
    "            else:\n",
    "                mid_channels = channels\n",
    "\n",
    "            if in_channels != channels:\n",
    "                if cfg_dict['up_kernel_size'] == 3:\n",
    "                    conv.append(conv3x3(in_channels, channels))\n",
    "                elif cfg_dict['up_kernel_size'] == 1:\n",
    "                    conv.append(conv1x1(in_channels, channels))\n",
    "                else:\n",
    "                    raise NotImplementedError\n",
    "\n",
    "            in_channels = channels\n",
    "\n",
    "\n",
    "            if 'num_blocks' in cfg_dict:\n",
    "                num_blocks = cfg_dict['num_blocks']\n",
    "                if cfg_dict['block_type'] == 'sew':\n",
    "                    for _ in range(num_blocks):\n",
    "                        conv.append(SEWBlock(in_channels, mid_channels, connect_f))\n",
    "                elif cfg_dict['block_type'] == 'plain':\n",
    "                    for _ in range(num_blocks):\n",
    "                        conv.append(PlainBlock(in_channels, mid_channels))\n",
    "                elif cfg_dict['block_type'] == 'basic':\n",
    "                    for _ in range(num_blocks):\n",
    "                        conv.append(BasicBlock(in_channels, mid_channels))\n",
    "                else:\n",
    "                    raise NotImplementedError\n",
    "\n",
    "            if 'k_pool' in cfg_dict:\n",
    "                k_pool = cfg_dict['k_pool']\n",
    "                conv.append(layer.SeqToANNContainer(nn.MaxPool2d(k_pool, k_pool)))\n",
    "\n",
    "        conv.append(nn.Flatten(2))\n",
    "\n",
    "        self.conv = nn.Sequential(*conv)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x = torch.zeros([1, 1, 128, 128])\n",
    "            for m in self.conv.modules():\n",
    "                if isinstance(m, nn.MaxPool2d):\n",
    "                    x = m(x)\n",
    "            out_features = x.numel() * in_channels\n",
    "\n",
    "        self.out = nn.Linear(out_features, num_classes, bias=True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = x.permute(1, 0, 2, 3, 4)  # [T, N, 2, *, *]\n",
    "        x = self.conv(x)\n",
    "        return self.out(x.mean(0))\n",
    "\n",
    "def SEWResNet(connect_f):\n",
    "    layer_list = [\n",
    "        {'channels': 32, 'up_kernel_size': 1, 'mid_channels': 32, 'num_blocks': 1, 'block_type': 'sew', 'k_pool': 2},\n",
    "        {'channels': 32, 'up_kernel_size': 1, 'mid_channels': 32, 'num_blocks': 1, 'block_type': 'sew', 'k_pool': 2},\n",
    "        {'channels': 32, 'up_kernel_size': 1, 'mid_channels': 32, 'num_blocks': 1, 'block_type': 'sew', 'k_pool': 2},\n",
    "        {'channels': 32, 'up_kernel_size': 1, 'mid_channels': 32, 'num_blocks': 1, 'block_type': 'sew', 'k_pool': 2},\n",
    "        {'channels': 32, 'up_kernel_size': 1, 'mid_channels': 32, 'num_blocks': 1, 'block_type': 'sew', 'k_pool': 2},\n",
    "        {'channels': 32, 'up_kernel_size': 1, 'mid_channels': 32, 'num_blocks': 1, 'block_type': 'sew', 'k_pool': 2},\n",
    "        {'channels': 32, 'up_kernel_size': 1, 'mid_channels': 32, 'num_blocks': 1, 'block_type': 'sew', 'k_pool': 2},\n",
    "    ]\n",
    "    num_classes = 11\n",
    "    return ResNetN(layer_list, num_classes, connect_f)\n",
    "\n",
    "def PlainNet(*args, **kwargs):\n",
    "    layer_list = [\n",
    "        {'channels': 32, 'up_kernel_size': 1, 'mid_channels': 32, 'num_blocks': 1, 'block_type': 'plain', 'k_pool': 2},\n",
    "        {'channels': 32, 'up_kernel_size': 1, 'mid_channels': 32, 'num_blocks': 1, 'block_type': 'plain', 'k_pool': 2},\n",
    "        {'channels': 32, 'up_kernel_size': 1, 'mid_channels': 32, 'num_blocks': 1, 'block_type': 'plain', 'k_pool': 2},\n",
    "        {'channels': 32, 'up_kernel_size': 1, 'mid_channels': 32, 'num_blocks': 1, 'block_type': 'plain', 'k_pool': 2},\n",
    "        {'channels': 32, 'up_kernel_size': 1, 'mid_channels': 32, 'num_blocks': 1, 'block_type': 'plain', 'k_pool': 2},\n",
    "        {'channels': 32, 'up_kernel_size': 1, 'mid_channels': 32, 'num_blocks': 1, 'block_type': 'plain', 'k_pool': 2},\n",
    "        {'channels': 32, 'up_kernel_size': 1, 'mid_channels': 32, 'num_blocks': 1, 'block_type': 'plain', 'k_pool': 2},\n",
    "    ]\n",
    "    num_classes = 11\n",
    "    return ResNetN(layer_list, num_classes)\n",
    "\n",
    "def SpikingResNet(*args, **kwargs):\n",
    "    layer_list = [\n",
    "        {'channels': 32, 'up_kernel_size': 1, 'mid_channels': 32, 'num_blocks': 1, 'block_type': 'basic', 'k_pool': 2},\n",
    "        {'channels': 32, 'up_kernel_size': 1, 'mid_channels': 32, 'num_blocks': 1, 'block_type': 'basic', 'k_pool': 2},\n",
    "        {'channels': 32, 'up_kernel_size': 1, 'mid_channels': 32, 'num_blocks': 1, 'block_type': 'basic', 'k_pool': 2},\n",
    "        {'channels': 32, 'up_kernel_size': 1, 'mid_channels': 32, 'num_blocks': 1, 'block_type': 'basic', 'k_pool': 2},\n",
    "        {'channels': 32, 'up_kernel_size': 1, 'mid_channels': 32, 'num_blocks': 1, 'block_type': 'basic', 'k_pool': 2},\n",
    "        {'channels': 32, 'up_kernel_size': 1, 'mid_channels': 32, 'num_blocks': 1, 'block_type': 'basic', 'k_pool': 2},\n",
    "        {'channels': 32, 'up_kernel_size': 1, 'mid_channels': 32, 'num_blocks': 1, 'block_type': 'basic', 'k_pool': 2},\n",
    "    ]\n",
    "    num_classes = 11\n",
    "    return ResNetN(layer_list, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe4f13a-1316-4b07-b6b8-55617a24acab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
