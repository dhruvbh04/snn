{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d612395b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Parameters: 130939\n",
      "Output Shape: torch.Size([16, 4, 11])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import snntorch as snn\n",
    "from snntorch import surrogate\n",
    "from snntorch import utils\n",
    "\n",
    "# Hyperparameters from Appendix A.1\n",
    "ALPHA = 2.0         # Slope parameter for surrogate gradient [cite: 560]\n",
    "V_TH = 1.0          # Firing threshold [cite: 560]\n",
    "V_RESET = 0.0       # Reset potential [cite: 560]\n",
    "LEARN_BETA = True   # PLIF: Learnable membrane time constant \n",
    "\n",
    "# Define the Surrogate Gradient Function (ArcTan)\n",
    "spike_grad = surrogate.atan(alpha=ALPHA)\n",
    "\n",
    "class SEWBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Spike-Element-Wise (SEW) Residual Block with ADD operation.\n",
    "    Ref: Section 3.3, Eq (9), and Fig 1(c)[cite: 139].\n",
    "    \"\"\"\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        # The Residual Path F(x): Conv -> BN -> SN -> Conv -> BN -> SN\n",
    "        # Note: 7B-Net maintains 32 channels throughout.\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(channels)\n",
    "        self.sn1 = snn.Leaky(beta=0.5, threshold=V_TH, reset_mechanism='zero', \n",
    "                             spike_grad=spike_grad, init_hidden=True, learn_beta=LEARN_BETA)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(channels)\n",
    "        self.sn2 = snn.Leaky(beta=0.5, threshold=V_TH, reset_mechanism='zero', \n",
    "                             spike_grad=spike_grad, init_hidden=True, learn_beta=LEARN_BETA)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: Input Spikes S^l[t]\n",
    "        \n",
    "        # --- Residual Mapping A^l[t] = SN(F(x)) ---\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.sn1(out) \n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.sn2(out) # This is A^l[t]\n",
    "        \n",
    "        # --- Element-Wise Function g(A, S) = ADD ---\n",
    "        # \"SEW ResNet can relieve infinite outputs... output no larger than k+1\" \n",
    "        return out + x \n",
    "\n",
    "class Net7B(nn.Module):\n",
    "    \"\"\"\n",
    "    7B-Net Architecture for DVS Gesture.\n",
    "    Structure: c32k3s1-BN-PLIF-{SEW Block-MPk2s2}*7-FC11 \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 1. Stem: c32k3s1-BN-PLIF\n",
    "        # Input channels = 2 (DVS Gesture often uses 2 channels: on/off events)\n",
    "        self.conv1 = nn.Conv2d(2, 32, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        # Initial PLIF neuron\n",
    "        self.sn1 = snn.Leaky(beta=0.5, threshold=V_TH, reset_mechanism='zero', \n",
    "                             spike_grad=spike_grad, init_hidden=True, learn_beta=LEARN_BETA)\n",
    "        \n",
    "        # 2. Body: {SEW Block - MPk2s2} * 7\n",
    "        # The paper repeats this structure 7 times.\n",
    "        self.layers = nn.ModuleList()\n",
    "        for _ in range(7):\n",
    "            self.layers.append(SEWBlock(32))\n",
    "            self.layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "            \n",
    "        # 3. Head: FC11\n",
    "        # DVS Gesture inputs are 128x128. After 7 MaxPools (reduction 2^7 = 128),\n",
    "        # spatial dim is 1x1. Channels = 32. Flatten -> 32 inputs.\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(32, 11) # 11 Classes for DVS Gesture\n",
    "        \n",
    "        # Output Integration Layer (Readout)\n",
    "        # We use a non-resetting Leaky layer to accumulate potential (votes) over time.\n",
    "        self.final_integ = snn.Leaky(beta=0.5, threshold=1e9, reset_mechanism='none', \n",
    "                                     spike_grad=spike_grad, init_hidden=True, \n",
    "                                     learn_beta=LEARN_BETA, output=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (Time_Steps, Batch_Size, Channels, Height, Width)\n",
    "        \n",
    "        # Reset hidden states (membranes) at start of batch\n",
    "        utils.reset(self.conv1) # Just in case\n",
    "        utils.reset(self.sn1)\n",
    "        for layer in self.layers:\n",
    "            utils.reset(layer)\n",
    "        utils.reset(self.final_integ)\n",
    "        \n",
    "        spk_rec = []\n",
    "        mem_rec = []\n",
    "        \n",
    "        # Loop over time dimension\n",
    "        for step in range(x.size(0)):\n",
    "            t_input = x[step]\n",
    "            \n",
    "            # Stem\n",
    "            out = self.conv1(t_input)\n",
    "            out = self.bn1(out)\n",
    "            out = self.sn1(out)\n",
    "            \n",
    "            # 7B Layers (SEW + MaxPool repeats)\n",
    "            for layer in self.layers:\n",
    "                out = layer(out)\n",
    "            \n",
    "            # Classification Head\n",
    "            out = self.flatten(out)\n",
    "            out = self.fc(out)\n",
    "            spk, mem = self.final_integ(out)\n",
    "            \n",
    "            spk_rec.append(spk)\n",
    "            mem_rec.append(mem)\n",
    "        \n",
    "        # Return stack of membrane potentials for CrossEntropyLoss\n",
    "        return torch.stack(mem_rec)\n",
    "\n",
    "# --- Example Usage ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Create the model\n",
    "    model = Net7B()\n",
    "    \n",
    "    # Input: 16 Time Steps, Batch Size 4, 2 Channels, 128x128 Resolution\n",
    "    # Note: T=16 is used in the paper for DVS Gesture \n",
    "    dummy_input = torch.randn(16, 4, 2, 128, 128)\n",
    "    \n",
    "    # Forward Pass\n",
    "    output_mem = model(dummy_input)\n",
    "    \n",
    "    print(f\"Model Parameters: {sum(p.numel() for p in model.parameters())}\")\n",
    "    print(f\"Output Shape: {output_mem.shape}\") # Should be [16, 4, 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0587e9a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
