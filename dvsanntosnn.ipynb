{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DVS Gesture Classification: ANN to SNN (snntorch)\n",
    "\n",
    "This notebook follows the DVS Gesture setup from `dvsges.ipynb` and performs ANN-to-SNN conversion using `snntorch` (manual weight transfer).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dedbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import tonic\n",
    "import tonic.transforms as transforms\n",
    "from tonic import DiskCachedDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "import snntorch as snn\n",
    "from snntorch import surrogate\n",
    "from snntorch import utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371331c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch, 'xpu') and torch.xpu.is_available():\n",
    "    device = torch.device('xpu')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f'Running on: {device}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eb6558",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_size = tonic.datasets.DVSGesture.sensor_size\n",
    "n_time_bins = 30\n",
    "batch_size = 16\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToFrame(sensor_size=sensor_size, n_time_bins=n_time_bins),\n",
    "])\n",
    "\n",
    "train_set = tonic.datasets.DVSGesture(save_to='./data', train=True, transform=transform)\n",
    "test_set = tonic.datasets.DVSGesture(save_to='./data', train=False, transform=transform)\n",
    "\n",
    "seq_loader_args = {\n",
    "    'batch_size': batch_size,\n",
    "    'collate_fn': tonic.collation.PadTensors(batch_first=False),\n",
    "    'shuffle': True,\n",
    "    'num_workers': 2,\n",
    "    'pin_memory': True\n",
    "}\n",
    "\n",
    "train_seq_loader = DataLoader(train_set, **seq_loader_args)\n",
    "test_seq_loader = DataLoader(test_set, **seq_loader_args)\n",
    "\n",
    "data, targets = next(iter(train_seq_loader))\n",
    "print(f'Sequence batch shape [T, B, C, H, W]: {data.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502b4cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AggregateFrameDataset(Dataset):\n",
    "    # Convert [T, C, H, W] event frames into one ANN frame [C, H, W].\n",
    "    def __init__(self, base_dataset):\n",
    "        self.base_dataset = base_dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        frames, target = self.base_dataset[idx]\n",
    "        frames = torch.as_tensor(frames, dtype=torch.float32)\n",
    "        ann_frame = frames.mean(dim=0)\n",
    "        target = torch.as_tensor(target, dtype=torch.long)\n",
    "        return ann_frame, target\n",
    "\n",
    "# Cache transformed samples on disk: first run is slower, next runs are much faster.\n",
    "train_cached = DiskCachedDataset(train_set, cache_path='./cache/dvsgesture_ann_train')\n",
    "test_cached = DiskCachedDataset(test_set, cache_path='./cache/dvsgesture_ann_test')\n",
    "\n",
    "train_ann_set = AggregateFrameDataset(train_cached)\n",
    "test_ann_set = AggregateFrameDataset(test_cached)\n",
    "\n",
    "# Windows/Jupyter often performs better with fewer workers for small random reads.\n",
    "ann_num_workers = 0 if os.name == 'nt' else 2\n",
    "ann_loader_args = {\n",
    "    'batch_size': batch_size,\n",
    "    'shuffle': True,\n",
    "    'num_workers': ann_num_workers,\n",
    "    'pin_memory': torch.cuda.is_available(),\n",
    "}\n",
    "if ann_num_workers > 0:\n",
    "    ann_loader_args['persistent_workers'] = True\n",
    "\n",
    "train_ann_loader = DataLoader(train_ann_set, **ann_loader_args)\n",
    "test_ann_loader = DataLoader(test_ann_set, **ann_loader_args)\n",
    "\n",
    "x_ann, y_ann = next(iter(train_ann_loader))\n",
    "print(f'ANN batch shape [B, C, H, W]: {x_ann.shape}')\n",
    "print(f'ANN DataLoader workers: {ann_num_workers}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANNNet(nn.Module):\n",
    "    def __init__(self, num_classes=11):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(2, 16, kernel_size=5, stride=2, padding=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2, padding=2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(32 * 8 * 8, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "ann_model = ANNNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(ann_model.parameters(), lr=2e-3)\n",
    "\n",
    "ann_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ann(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.float().to(device)\n",
    "            y = y.long().to(device)\n",
    "            logits = model(x)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.numel()\n",
    "    return correct / max(total, 1)\n",
    "\n",
    "num_epochs = 15\n",
    "for epoch in range(num_epochs):\n",
    "    ann_model.train()\n",
    "    running_loss = 0.0\n",
    "    steps = 0\n",
    "\n",
    "    for x, y in tqdm(train_ann_loader, desc=f'ANN Epoch {epoch + 1}/{num_epochs}'):\n",
    "        x = x.float().to(device)\n",
    "        y = y.long().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = ann_model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        steps += 1\n",
    "\n",
    "    train_acc = evaluate_ann(ann_model, train_ann_loader)\n",
    "    test_acc = evaluate_ann(ann_model, test_ann_loader)\n",
    "    avg_loss = running_loss / max(steps, 1)\n",
    "    print(f'Epoch {epoch + 1}: loss={avg_loss:.4f}, train_acc={train_acc:.4f}, test_acc={test_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 0.5\n",
    "spike_grad = surrogate.atan()\n",
    "\n",
    "class SNNNet(nn.Module):\n",
    "    def __init__(self, num_classes=11):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(2, 16, kernel_size=5, stride=2, padding=2)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.lif1 = snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2, padding=2)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.lif2 = snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(32 * 8 * 8, num_classes)\n",
    "        self.lif3 = snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True, output=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.lif1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.lif2(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        spk_out, mem_out = self.lif3(x)\n",
    "        return spk_out, mem_out\n",
    "\n",
    "def convert_ann_to_snn(ann_model):\n",
    "    snn_model = SNNNet().to(device)\n",
    "    snn_model.conv1.weight.data.copy_(ann_model.conv1.weight.data)\n",
    "    snn_model.conv1.bias.data.copy_(ann_model.conv1.bias.data)\n",
    "    snn_model.conv2.weight.data.copy_(ann_model.conv2.weight.data)\n",
    "    snn_model.conv2.bias.data.copy_(ann_model.conv2.bias.data)\n",
    "    snn_model.fc1.weight.data.copy_(ann_model.fc1.weight.data)\n",
    "    snn_model.fc1.bias.data.copy_(ann_model.fc1.bias.data)\n",
    "    return snn_model\n",
    "\n",
    "snn_model = convert_ann_to_snn(ann_model)\n",
    "print('Converted ANN to SNN (snntorch) via weight transfer.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_snn(model, loader, sim_steps=30):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(loader, desc='SNN Eval'):\n",
    "            x = x.float().to(device)\n",
    "            y = y.long().to(device)\n",
    "\n",
    "            utils.reset(model)\n",
    "            spk_sum = 0\n",
    "            for _ in range(sim_steps):\n",
    "                spk_out, _ = model(x)\n",
    "                spk_sum = spk_sum + spk_out\n",
    "\n",
    "            preds = spk_sum.argmax(dim=1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += y.numel()\n",
    "\n",
    "    return correct / max(total, 1)\n",
    "\n",
    "ann_test_acc = evaluate_ann(ann_model, test_ann_loader)\n",
    "snn_test_acc = evaluate_snn(snn_model, test_ann_loader, sim_steps=30)\n",
    "\n",
    "torch.save(ann_model.state_dict(), 'ann_dvsgesture.pth')\n",
    "torch.save(snn_model.state_dict(), 'snn_from_ann_dvsgesture_snntorch.pth')\n",
    "\n",
    "print(f'ANN test accuracy: {ann_test_acc:.4f}')\n",
    "print(f'SNN test accuracy: {snn_test_acc:.4f}')\n",
    "print('Saved ann_dvsgesture.pth and snn_from_ann_dvsgesture_snntorch.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}